# Story 16.3: Performance and Security Validation

**Status**: unassigned
**Parent**: Story 16
**Created**: 2025-11-18 23:30
**Priority**: HIGH
**Estimated Effort**: 4 hours
**Phase**: 8.3 (Week 4, Day 1)
**Depends on**: Story 16.2 (integration tests must pass first)

## Description

Validate performance benchmarks and security requirements for all new session tracking features. Ensure <5% overhead and verify security defaults.

**Scope**:
- Performance benchmarks (periodic checker, file watcher, template caching)
- Security validation (safe defaults, opt-in model, no unintended indexing)

## Acceptance Criteria

### Performance Tests

#### Periodic Checker Overhead
- [ ] Benchmark periodic checker adds <5% overhead
- [ ] Test with baseline (no checker) vs with checker
- [ ] Measure over 60-second period
- [ ] Verify overhead calculation correct

**File**: `tests/session_tracking/test_performance.py`

#### File Watcher Scalability
- [ ] Test with 1000+ sessions (no degradation)
- [ ] Verify discovery time <5 seconds
- [ ] Verify memory usage reasonable
- [ ] Test with mixed file types (old, new, large, small)

#### Template Resolution Caching
- [ ] Test template reads cached (avoid re-reads)
- [ ] Verify cache invalidation on file changes
- [ ] Measure cache hit rate (>90% after warmup)
- [ ] Test performance improvement (cached vs uncached)

#### Session Discovery Performance
- [ ] Test large directories (10,000+ files)
- [ ] Verify filtering performance (keep_length_days)
- [ ] Test glob pattern performance
- [ ] Measure discovery time scaling

### Security Tests

#### Safe Defaults
- [ ] Verify session tracking disabled by default (`enabled: false`)
- [ ] Verify auto-summarize disabled by default (`auto_summarize: false`)
- [ ] Verify rolling window prevents bulk indexing (`keep_length_days: 7`)
- [ ] Verify no LLM costs by default

**File**: `tests/session_tracking/test_security.py`

#### Opt-In Model
- [ ] Verify explicit enable required (CLI or config)
- [ ] Verify confirmation required for dangerous operations (--days 0)
- [ ] Verify dry-run mode default for manual sync
- [ ] Verify clear user communication (warnings, help text)

#### No Unintended Indexing
- [ ] Verify historical sessions NOT indexed on startup
- [ ] Verify only sessions within rolling window indexed
- [ ] Verify manual sync requires explicit command
- [ ] Verify disabled state respected (no indexing)

### Coverage Requirements
- [ ] All performance tests meet requirements (<5% overhead)
- [ ] All security requirements met (100% coverage)

## Implementation Details

### Performance Benchmark Structure

**Example: Periodic Checker Overhead** (~80 LOC):
```python
def test_periodic_checker_overhead():
    """Verify periodic checker adds <5% overhead."""
    iterations = 100

    # Baseline: session manager without checker
    baseline_times = []
    for _ in range(iterations):
        start = time.time()
        manager = SessionManager(watch_path=Path("/tmp"), inactivity_timeout=300)
        manager.start()
        time.sleep(0.1)
        manager.stop()
        baseline_times.append(time.time() - start)

    baseline_avg = sum(baseline_times) / len(baseline_times)

    # With checker
    checker_times = []
    for _ in range(iterations):
        start = time.time()
        manager = SessionManager(watch_path=Path("/tmp"), inactivity_timeout=300)
        manager.start()
        task = asyncio.create_task(check_inactive_sessions_periodically(manager, interval_seconds=0.05))
        time.sleep(0.1)
        task.cancel()
        manager.stop()
        checker_times.append(time.time() - start)

    checker_avg = sum(checker_times) / len(checker_times)

    # Calculate overhead
    overhead = (checker_avg - baseline_avg) / baseline_avg
    print(f"Overhead: {overhead * 100:.2f}%")
    assert overhead < 0.05  # <5%
```

### Security Test Structure

**Example: Safe Defaults** (~40 LOC):
```python
def test_disabled_by_default():
    """Verify session tracking is disabled by default."""
    config = SessionTrackingConfig()
    assert config.enabled is False
    assert config.auto_summarize is False
    assert config.keep_length_days == 7

def test_confirmation_required_for_all_history():
    """Verify CLI requires confirmation for --days 0."""
    result = subprocess.run(
        ["graphiti-mcp", "session-tracking", "sync", "--days", "0"],
        capture_output=True,
        text=True,
    )

    assert result.returncode != 0
    assert "--confirm" in result.stdout or "confirmation required" in result.stdout.lower()
```

### Test Count
- **Total new tests**: ~10 performance + ~8 security = 18 tests
- **Estimated runtime**: 2-3 minutes (performance benchmarks)

## Dependencies

- Story 16.2 (Integration Test Validation) - REQUIRED
- Stories 9-15 (all implementation complete) - REQUIRED

## Cross-Cutting Requirements

See parent sprint `.claude/implementation/CROSS_CUTTING_REQUIREMENTS.md`:
- Performance: <5% overhead verified
- Security: No exposure of sensitive information
- Testing: Platform-specific benchmarks (Windows + Unix)
