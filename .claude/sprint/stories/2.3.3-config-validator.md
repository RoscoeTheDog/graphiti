# Story 2.3.3: Configuration Validator Implementation

**Status**: unassigned
**Parent**: Story 2.3
**Created**: 2025-11-17 16:45
**Priority**: HIGH (enables Story 2.3)
**Depends on**: Story 2.3.2

## WHO
- **Affected**: All Graphiti users, configuration maintainers
- **Stakeholders**: MCP server operators, developers, CI/CD pipelines

## WHAT
Implement a configuration validator that verifies `graphiti.config.json` loads correctly, validates against Pydantic schemas, and provides clear error messages for configuration issues.

## WHEN
**Dependency**: After Story 2.3.2 (schema mismatches fixed)
**Sequencing**: Third in Story 2.3.x series
**Enables**: Story 2.3 (configurable filtering - need validator to test configs)

## WHERE
**New files**:
- `mcp_server/config_validator.py` (new) - Validator implementation
- `tests/test_config_validator.py` (new) - Unit tests

**Modified files**:
- `mcp_server/unified_config.py` - Add validation methods
- `graphiti.config.json` - Add `$schema` field for IDE support
- `CONFIGURATION.md` - Document validator usage

**CLI integration** (optional):
- `python -m mcp_server.config_validator` - Validate config file

## WHY

### User Problem
Users editing `graphiti.config.json` manually have no way to know if their config is valid until:
1. They start the MCP server → runtime error
2. Pydantic validation fails → cryptic error messages
3. Typos in field names → silently ignored (defaults used)

### Business Value
- **Developer Experience**: Catch errors early (edit time > runtime)
- **Reliability**: Validate configs before deployment
- **CI/CD Integration**: Automated config validation in pipelines
- **Documentation**: Validator output teaches users about schema

### Technical Need
- **Pre-deployment validation**: Check configs before MCP server starts
- **Schema enforcement**: Ensure JSON matches Pydantic models
- **Clear error messages**: "Unknown field 'watch_directories', did you mean 'watch_path'?"
- **IDE support**: JSON Schema for autocomplete/validation

## Description

### Validator Capabilities

**Level 1: Syntax Validation**
- ✅ Valid JSON syntax
- ✅ No trailing commas (strict JSON)
- ✅ Proper quote escaping

**Level 2: Schema Validation**
- ✅ All fields match Pydantic model
- ✅ Types correct (string, int, bool, nested objects)
- ✅ No unknown fields (typo detection)
- ✅ Required fields present

**Level 3: Semantic Validation**
- ✅ File paths exist (if `validate_paths=True`)
- ✅ URIs well-formed (database URIs, API endpoints)
- ✅ Environment variables defined (e.g., `NEO4J_PASSWORD` if `password_env` set)
- ✅ Port numbers in valid range (1-65535)
- ✅ Timeouts reasonable (not 0, not negative)

**Level 4: Cross-Field Validation**
- ✅ Database backend matches config used (if `backend=neo4j`, then `neo4j` section required)
- ✅ LLM provider matches config used (if `provider=openai`, then `openai.api_key_env` required)
- ✅ Embedder provider matches LLM provider (or explicit embedder config)

### Validator Output

**Success**:
```
✅ Configuration valid: ./graphiti.config.json

Schema: graphiti-config v1.0.0
Database: neo4j (bolt://localhost:7687)
LLM: openai (gpt-4.1-mini)
Embedder: openai (text-embedding-3-small)
Session Tracking: disabled

No issues found.
```

**Failure** (helpful errors):
```
❌ Configuration invalid: ./graphiti.config.json

Issues found:

[ERROR] session_tracking.watch_directories: Unknown field
  → Did you mean 'watch_path'? (string, not array)
  → Location: line 98, column 5

[ERROR] session_tracking.inactivity_timeout_minutes: Unknown field
  → Did you mean 'inactivity_timeout'? (Note: units are seconds, not minutes)
  → Location: line 99, column 5

[WARNING] database.neo4j.uri: Environment variable NEO4J_PASSWORD not set
  → Required by: database.neo4j.password_env
  → Fix: export NEO4J_PASSWORD="your-password"

[WARNING] session_tracking.watch_path: Path does not exist
  → Value: /custom/path
  → Fix: Create directory or update path

Summary: 2 errors, 2 warnings
```

## Acceptance Criteria

### Validator Implementation
- [ ] Create `mcp_server/config_validator.py`:
  - [ ] `ConfigValidator` class with methods:
    - [ ] `validate_syntax(file_path)` - JSON syntax check
    - [ ] `validate_schema(file_path)` - Pydantic validation
    - [ ] `validate_semantics(config, check_paths=True, check_env=True)` - Semantic checks
    - [ ] `validate_cross_fields(config)` - Cross-field validation
    - [ ] `validate_all(file_path, level="full")` - Run all validations
  - [ ] Return `ValidationResult` dataclass:
    ```python
    @dataclass
    class ValidationResult:
        valid: bool
        errors: List[ValidationError]
        warnings: List[ValidationWarning]
        config: Optional[GraphitiConfig]
    ```

### Validation Checks
- [ ] **Syntax** (JSON parsing):
  - [ ] Catch `json.JSONDecodeError`
  - [ ] Report line/column of syntax errors
- [ ] **Schema** (Pydantic validation):
  - [ ] Catch `pydantic.ValidationError`
  - [ ] Extract field names and error messages
  - [ ] Suggest corrections (field name typos)
- [ ] **Semantic** (value validation):
  - [ ] Database URI format: `bolt://`, `redis://`, etc.
  - [ ] File paths exist (if `check_paths=True`)
  - [ ] Environment variables defined (if `check_env=True`)
  - [ ] Port numbers: 1-65535
  - [ ] Timeouts: > 0
- [ ] **Cross-field** (relationships):
  - [ ] If `backend=neo4j`, then `neo4j` section present
  - [ ] If `provider=openai`, then `openai.api_key_env` present
  - [ ] If `session_tracking.enabled=true`, then `watch_path` not null

### Error Messages
- [ ] Clear, actionable error messages
- [ ] Suggest fixes (not just "field invalid")
- [ ] Include line/column numbers (from JSON)
- [ ] Use "Did you mean X?" for typos
- [ ] Distinguish ERROR (blocks) vs WARNING (informational)

### CLI Interface
- [ ] `python -m mcp_server.config_validator` - Validate default config
- [ ] `python -m mcp_server.config_validator <path>` - Validate specific file
- [ ] Flags:
  - [ ] `--level {syntax|schema|semantic|full}` - Validation level (default: full)
  - [ ] `--no-path-check` - Skip file path existence checks
  - [ ] `--no-env-check` - Skip environment variable checks
  - [ ] `--json` - Output JSON format (for CI/CD)
- [ ] Exit codes:
  - [ ] 0 = valid
  - [ ] 1 = errors found
  - [ ] 2 = warnings only
  - [ ] 3 = validator error (not config error)

### Integration with GraphitiConfig
- [ ] Add `GraphitiConfig.validate()` method:
  ```python
  @classmethod
  def validate(cls, config_path: str) -> ValidationResult:
      validator = ConfigValidator()
      return validator.validate_all(config_path)
  ```
- [ ] Optionally call validator in `from_file()`:
  ```python
  @classmethod
  def from_file(cls, config_path: str, validate: bool = True):
      if validate:
          result = cls.validate(config_path)
          if not result.valid:
              raise ConfigValidationError(result.errors)
      # ... existing logic
  ```

### Testing
- [ ] Unit tests in `tests/test_config_validator.py`:
  - [ ] Test valid config (no errors)
  - [ ] Test syntax errors (invalid JSON)
  - [ ] Test schema errors (unknown fields, type mismatches)
  - [ ] Test semantic errors (bad URIs, missing paths)
  - [ ] Test cross-field errors (backend mismatch)
  - [ ] Test warning generation (missing env vars)
  - [ ] Test typo suggestions (field name similarity)
  - [ ] Test CLI interface (exit codes, output formats)
- [ ] Integration tests:
  - [ ] Validate `graphiti.config.json` in repo (should pass)
  - [ ] Test against malformed configs (should fail)

### Documentation
- [ ] Update `CONFIGURATION.md`:
  - [ ] Add "Validating Configuration" section
  - [ ] Document CLI usage
  - [ ] Show example error messages
  - [ ] Explain validation levels
- [ ] Add JSON Schema:
  - [ ] Generate `graphiti.config.schema.json` from Pydantic models
  - [ ] Add `$schema` field to `graphiti.config.json`:
    ```json
    {
      "$schema": "./graphiti.config.schema.json",
      "version": "1.0.0",
      ...
    }
    ```
  - [ ] Enables IDE autocomplete and validation

## Implementation Notes

### Field Name Typo Detection

Use fuzzy matching to suggest corrections:
```python
from difflib import get_close_matches

def suggest_field_name(unknown_field: str, valid_fields: List[str]) -> Optional[str]:
    matches = get_close_matches(unknown_field, valid_fields, n=1, cutoff=0.6)
    return matches[0] if matches else None

# Example:
# suggest_field_name("watch_directories", ["watch_path", "enabled"]) → "watch_path"
```

### URI Validation

```python
from urllib.parse import urlparse

def validate_uri(uri: str, expected_schemes: List[str]) -> bool:
    parsed = urlparse(uri)
    return parsed.scheme in expected_schemes

# Example:
# validate_uri("bolt://localhost:7687", ["bolt", "neo4j"]) → True
# validate_uri("invalid", ["bolt"]) → False
```

### Environment Variable Checking

```python
import os

def check_env_var(env_var_name: str) -> Tuple[bool, Optional[str]]:
    value = os.environ.get(env_var_name)
    if value is None:
        return False, f"Environment variable {env_var_name} not set"
    if value == "":
        return False, f"Environment variable {env_var_name} is empty"
    return True, None
```

### JSON Schema Generation

```python
# Generate JSON schema from Pydantic model
schema = GraphitiConfig.model_json_schema()

with open("graphiti.config.schema.json", "w") as f:
    json.dump(schema, f, indent=2)
```

### Validation Levels

**Why multiple levels?**
- **Syntax**: Fast, catches basic errors (malformed JSON)
- **Schema**: Moderate, ensures structure correct (field names, types)
- **Semantic**: Slower, checks values make sense (paths exist, URIs valid)
- **Full**: All checks (most thorough, use in CI/CD)

Users can skip semantic checks for faster validation during development.

## Cross-Cutting Requirements

- [ ] **Type Safety**: Pydantic models, typed validation results
- [ ] **Error Handling**: Catch all validation errors, never crash
- [ ] **Logging**: Log validation attempts (INFO), errors (ERROR)
- [ ] **Testing**: >80% coverage for config_validator.py
- [ ] **Performance**: Validation completes in <1 second for typical config
- [ ] **Documentation**: Clear examples, error message reference
- [ ] **Usability**: Helpful error messages, actionable suggestions

## Success Metrics

- [ ] Validator catches ALL schema mismatches from Story 2.3.2
- [ ] Error messages clearly explain what's wrong + how to fix
- [ ] CI/CD pipeline uses validator (exit code 0 = valid)
- [ ] Users report config validation helpful (subjective)
- [ ] Zero runtime config errors after using validator

## CLI Usage Examples

```bash
# Validate default config
python -m mcp_server.config_validator
✅ Configuration valid: ./graphiti.config.json

# Validate specific file
python -m mcp_server.config_validator ~/.graphiti/graphiti.config.json

# Schema validation only (fast)
python -m mcp_server.config_validator --level schema

# Skip path checks (for CI without filesystem)
python -m mcp_server.config_validator --no-path-check

# JSON output for CI/CD
python -m mcp_server.config_validator --json
{
  "valid": true,
  "errors": [],
  "warnings": [],
  "summary": "No issues found"
}
```

## Related Stories

- **Depends on**: Story 2.3.2 (Schema Mismatch Fixes)
- **Enables**: Story 2.3 (Configurable Filtering System - need validator to test configs)
- **Enables**: Story 2.3.1 (Config Architecture Fix - validate migration worked)

## Estimated Effort

- Validator implementation: 3-4 hours
- Error message formatting: 1-2 hours
- CLI interface: 1 hour
- Testing: 2-3 hours
- JSON Schema generation: 1 hour
- Documentation: 1-2 hours
- Total: 9-13 hours
