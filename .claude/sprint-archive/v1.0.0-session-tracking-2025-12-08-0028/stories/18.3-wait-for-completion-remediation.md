# Story 18.3: Implement wait_for_completion Parameter

**Type**: remediation
**Remediation Type**: enhancement
**Parent**: Story 18
**Priority**: P1
**Status**: completed
**Created**: 2025-11-28
**Completed**: 2025-11-28

---

## Context

**Original Story**: 18 - MCP Tools Error Handling
**Current Status**: completed
**Issue**: AC-18.8 and AC-18.9 require a `wait_for_completion` parameter for `add_memory()` that blocks until processing completes (true) or returns immediately (false). The config option exists but the parameter is not implemented.

**Codebase Analysis**:
- Config: `mcp_server/unified_config.py` line 437 has `wait_for_completion_default: bool`
- Target: `mcp_server/graphiti_mcp_server.py` add_memory() function (line 1073)
- Current behavior: Always queues and returns immediately
- Required: Option to wait for processing completion

---

## Remediation Goal

Add `wait_for_completion` parameter to `add_memory()` function that:
- When `true`: Blocks until episode processing completes, returns actual result
- When `false`: Returns immediately after queueing (current behavior)
- Defaults to config value (`wait_for_completion_default`)

---

## Remediation Actions

### 1. Add Parameter to add_memory() Function Signature

**File**: `mcp_server/graphiti_mcp_server.py`
**Change**: Add wait_for_completion parameter

```python
@mcp.tool()
async def add_memory(
    name: str,
    episode_body: str,
    group_id: str | None = None,
    source: str = 'text',
    source_description: str = '',
    uuid: str | None = None,
    filepath: str | None = None,
    wait_for_completion: bool | None = None,  # ADD THIS
) -> str:
    """Add an episode to memory and optionally export to file.

    ...existing docstring...

    Args:
        ...existing args...
        wait_for_completion (bool, optional): If True, block until processing completes.
                                             If False, return immediately after queueing.
                                             Defaults to config value (mcp_tools.wait_for_completion_default).

    ...rest of docstring...
    """
```

### 2. Resolve wait_for_completion Default

**File**: `mcp_server/graphiti_mcp_server.py`
**Location**: Near start of add_memory() function body (after global declarations)

```python
async def add_memory(...):
    global graphiti_client, episode_queues, queue_workers

    # Resolve wait_for_completion from config if not provided
    should_wait = wait_for_completion
    if should_wait is None:
        should_wait = unified_config.mcp_tools.wait_for_completion_default

    if graphiti_client is None:
        # ... existing error handling ...
```

### 3. Implement Synchronous Wait Logic

**File**: `mcp_server/graphiti_mcp_server.py`
**Change**: Modify episode processing to support waiting

Replace the current queue-and-return logic with conditional behavior:

```python
        # =================================================================
        # Episode Processing (with wait_for_completion support)
        # =================================================================

        # Create an Event for synchronization if waiting
        processing_complete = asyncio.Event() if should_wait else None
        processing_result = {"success": False, "error": None, "episode_id": None}

        async def process_episode():
            nonlocal processing_result
            try:
                logger.info(f"Processing queued episode '{name}' for group_id: {group_id_str}")
                entity_types = ENTITY_TYPES if config.use_custom_entities else {}

                result = await client.add_episode(
                    name=name,
                    episode_body=episode_body,
                    source=source_type,
                    source_description=source_description,
                    group_id=group_id_str,
                    uuid=uuid,
                    reference_time=datetime.now(timezone.utc),
                    entity_types=entity_types,
                )

                processing_result["success"] = True
                processing_result["episode_id"] = str(result.uuid) if hasattr(result, 'uuid') else None
                logger.info(f"Episode '{name}' processed successfully")

            except Exception as e:
                error_msg = str(e)
                processing_result["error"] = error_msg
                logger.error(f"Error processing episode '{name}': {error_msg}")
            finally:
                if processing_complete:
                    processing_complete.set()

        # Initialize queue and add task
        if group_id_str not in episode_queues:
            episode_queues[group_id_str] = asyncio.Queue()

        await episode_queues[group_id_str].put(process_episode)

        if not queue_workers.get(group_id_str, False):
            asyncio.create_task(process_episode_queue(group_id_str))

        # =================================================================
        # Wait for Completion (if requested)
        # =================================================================
        if should_wait and processing_complete:
            try:
                # Wait with timeout to prevent indefinite blocking
                timeout = unified_config.mcp_tools.episode_timeout_seconds
                await asyncio.wait_for(processing_complete.wait(), timeout=timeout)
            except asyncio.TimeoutError:
                response = create_timeout_error(
                    operation="add_memory",
                    timeout_seconds=timeout,
                    suggestion=(
                        f"Episode processing timed out after {timeout}s. "
                        "The operation may still complete in the background. "
                        "Consider using wait_for_completion=false for long operations."
                    )
                )
                return format_response(response)

            # Check processing result
            if not processing_result["success"]:
                response = create_error(
                    category=ErrorCategory.INTERNAL,
                    message=f"Episode processing failed: {processing_result['error']}",
                    recoverable=True,
                    suggestion="Check the error message and retry."
                )
                return format_response(response)
```

### 4. Update Response Building for Sync Mode

**File**: `mcp_server/graphiti_mcp_server.py`
**Change**: Modify response section to reflect sync vs async mode

```python
        # =================================================================
        # Build Response
        # =================================================================
        processing_time_ms = (time.perf_counter() - start_time) * 1000

        if is_degraded:
            response = create_degraded(
                reason=degradation_reason or DegradationReason.LLM_UNAVAILABLE,
                message=f"Episode '{name}' stored with degraded functionality",
                limitations=limitations,
                episode_id=processing_result.get("episode_id") if should_wait else None,
                processing_time_ms=processing_time_ms,
                episode_name=name,
                group_id=group_id_str,
                saved_to=file_saved_path,
            )
            result = format_response(response)
            if file_warnings:
                result += f"\nWarning: {file_warnings[0]}"
            return result

        else:
            # Success response
            if should_wait:
                # Synchronous: processing completed
                msg = f"Episode '{name}' added successfully"
                if file_saved_path:
                    msg += f"\nSaved to {file_saved_path}"
                response = create_success(
                    message=msg,
                    episode_id=processing_result.get("episode_id"),
                    processing_time_ms=processing_time_ms,
                )
                result = format_response(response)
            else:
                # Asynchronous: just queued
                if file_saved_path:
                    msg = f"Episode '{name}' queued successfully\nSaved to {file_saved_path}"
                else:
                    msg = f"Episode '{name}' queued successfully"
                result = msg

            if file_warnings:
                result += f"\nWarning: {file_warnings[0]}"
            return result
```

### 5. Add Timeout Config (if not exists)

**File**: `mcp_server/unified_config.py`
**Check/Add**: Ensure timeout config exists for wait operations

```python
class MCPToolsBehaviorConfig(BaseModel):
    """Configuration for MCP tools behavior."""

    on_llm_unavailable: Literal["FAIL", "STORE_RAW", "QUEUE_RETRY"] = Field(...)
    wait_for_completion_default: bool = Field(
        default=True,
        description="Default value for wait_for_completion parameter"
    )
    episode_timeout_seconds: float = Field(
        default=60.0,
        description="Timeout in seconds when waiting for episode processing"
    )
```

---

## Testing

**File**: `tests/mcp_server/test_add_memory.py` (new or add to existing)

```python
import pytest
from unittest.mock import AsyncMock, patch, MagicMock

class TestWaitForCompletion:
    """Tests for wait_for_completion parameter (AC-18.8, AC-18.9)."""

    @pytest.mark.asyncio
    async def test_wait_for_completion_true_success(self):
        """Test synchronous mode returns after processing."""
        # Mock the graphiti client and processing
        with patch('mcp_server.graphiti_mcp_server.graphiti_client') as mock_client:
            mock_client.add_episode = AsyncMock(return_value=MagicMock(uuid="ep-123"))
            mock_client.llm_available = True

            result = await add_memory(
                name="Test Episode",
                episode_body="Test content",
                wait_for_completion=True
            )

            assert "added successfully" in result
            # Should include episode_id since we waited

    @pytest.mark.asyncio
    async def test_wait_for_completion_false_queued(self):
        """Test async mode returns immediately."""
        with patch('mcp_server.graphiti_mcp_server.graphiti_client') as mock_client:
            mock_client.llm_available = True

            result = await add_memory(
                name="Test Episode",
                episode_body="Test content",
                wait_for_completion=False
            )

            assert "queued successfully" in result

    @pytest.mark.asyncio
    async def test_wait_for_completion_default_from_config(self):
        """Test default comes from config."""
        with patch('mcp_server.graphiti_mcp_server.unified_config') as mock_config:
            mock_config.mcp_tools.wait_for_completion_default = True
            mock_config.mcp_tools.episode_timeout_seconds = 60.0

            # When wait_for_completion is None, should use config default
            # Test implementation respects config

    @pytest.mark.asyncio
    async def test_wait_for_completion_timeout(self):
        """Test timeout handling."""
        with patch('mcp_server.graphiti_mcp_server.graphiti_client') as mock_client:
            mock_client.llm_available = True
            # Mock slow processing that exceeds timeout

            result = await add_memory(
                name="Slow Episode",
                episode_body="Content",
                wait_for_completion=True
            )

            # Should return timeout error after configured timeout
```

---

## Acceptance Criteria

- [x] **(P1) AC-18.3.1**: add_memory() accepts wait_for_completion parameter
- [x] **(P1) AC-18.3.2**: wait_for_completion=true blocks until processing completes
- [x] **(P1) AC-18.3.3**: wait_for_completion=false returns immediately (current behavior)
- [x] **(P1) AC-18.3.4**: Default value comes from config (wait_for_completion_default)
- [x] **(P1) AC-18.3.5**: Timeout handling prevents indefinite blocking
- [x] **(P1) AC-18.3.6**: All tests pass

---

## Verification

1. Run `pytest tests/mcp_server/ -v`
2. Manual test with MCP client:
   - Call `add_memory` with `wait_for_completion=true` - should block and return result
   - Call `add_memory` with `wait_for_completion=false` - should return immediately
3. Verify config default is respected when parameter not provided

---

## Notes

- **Remediation Type**: enhancement (new functionality)
- **Auto-Created**: 2025-11-28
- **Created From**: Validation Story -18 findings
- **Original ACs**: AC-18.8 (add parameter), AC-18.9 (default to true)
- **Complexity**: Medium - requires asyncio Event synchronization
