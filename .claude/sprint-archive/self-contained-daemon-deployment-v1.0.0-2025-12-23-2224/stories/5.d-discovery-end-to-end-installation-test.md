# Story 5.d: Discovery - End-to-end Installation Test

**Status**: in_progress
**Created**: 2025-12-23
**Parent Story**: [Story 5: End-to-end installation test](5-end-to-end-installation-test.md)

## Executive Summary

This discovery phase analyzes the requirements for creating an integration test that validates the complete daemon installation flow works on a clean system. The test must simulate a fresh installation by removing `~/.graphiti/` and verify all components work independently of the project directory.

## Current State Analysis

### Existing Test Infrastructure

**Unit Tests** (✅ Comprehensive)
- `mcp_server/tests/test_package_installation.py` - VenvManager installation testing
  - Tests uv pip installation (preferred)
  - Tests fallback to standard pip
  - Tests repository detection
  - Tests installation validation
  - Tests error scenarios (missing venv, timeout, security)

- `mcp_server/tests/test_full_install_flow.py` - Integration testing
  - Tests complete install workflow (venv → package → wrappers → PATH)
  - Tests directory structure creation
  - Tests idempotent installation
  - Tests CLI command availability
  - Tests error handling (incompatible Python, package not found, wrapper generation)

**Installation Scripts** (✅ Production-ready)
- `mcp_server/daemon/manager.py` - DaemonManager (platform-agnostic interface)
  - Multi-step installation: Python validation → venv creation → package deployment → package installation → wrapper generation → service registration
  - Platform detection (Windows/macOS/Linux)
  - Comprehensive error handling with troubleshooting messages

- `mcp_server/daemon/bootstrap.py` - BootstrapService
  - Config-based daemon lifecycle management
  - Environment validation (venv exists, Python version)
  - MCP server process management

- `mcp_server/daemon/venv_manager.py` - VenvManager
  - Dedicated venv at `~/.graphiti/.venv/`
  - uv pip preferred, fallback to standard pip
  - Repository detection (searches upward 5 levels)
  - Installation validation

- `mcp_server/daemon/package_deployer.py` - PackageDeployer
  - Deploys mcp_server to `~/.graphiti/mcp_server/`
  - Makes daemon independent of project directory

- `mcp_server/daemon/wrapper_generator.py` - WrapperGenerator
  - Creates CLI wrappers in `~/.graphiti/bin/`
  - Platform-specific wrappers (Windows .cmd, Unix scripts)

### Test Coverage Gaps (Discovery Findings)

**Gap 1: Clean System Simulation** (❌ Missing)
- Current tests use `tmp_path` but don't test actual `~/.graphiti/` cleanup
- No test for "remove existing installation and reinstall" scenario
- No validation that daemon runs independently after project directory is removed

**Gap 2: End-to-End Installation Flow** (⚠️ Partial)
- `test_full_install_flow.py` tests individual components in isolation (mocked)
- No test that actually runs the full `graphiti-mcp daemon install` command
- No test that verifies service registration (NSSM/systemd/launchd)

**Gap 3: Independence Verification** (❌ Missing)
- No test that removes project directory after install
- No test that verifies daemon can start/stop without project directory
- No test that verifies MCP server responds on health endpoint

**Gap 4: Manual Steps Documentation** (⚠️ Partial)
- Admin privileges required for service registration (Windows NSSM, systemd)
- PATH configuration manual step
- No automated test for these scenarios

## Proposed Test Scenarios

### Scenario 1: Fresh Installation (P0 - Critical)
**Goal**: Validate complete installation flow from scratch

**Steps**:
1. Remove `~/.graphiti/` directory (clean state)
2. Run `graphiti-mcp daemon install`
3. Verify directory structure created:
   - `~/.graphiti/.venv/` (dedicated venv)
   - `~/.graphiti/mcp_server/` (deployed package)
   - `~/.graphiti/bin/` (CLI wrappers)
   - `~/.graphiti/graphiti.config.json` (config file)
   - `~/.graphiti/logs/` (log directory)
4. Verify venv contains installed mcp_server package
5. Verify wrappers are executable
6. Verify service is registered (platform-specific check)

**Expected Outcome**: All components installed successfully, daemon ready to start

### Scenario 2: Service Lifecycle (P0 - Critical)
**Goal**: Validate daemon can start/stop independently

**Steps**:
1. After fresh installation (Scenario 1)
2. Set `daemon.enabled = true` in config
3. Start bootstrap service (platform-specific command)
4. Verify MCP server process starts
5. Query health endpoint: `http://localhost:PORT/health`
6. Set `daemon.enabled = false` in config
7. Verify MCP server process stops gracefully
8. Stop bootstrap service

**Expected Outcome**: Bootstrap service manages MCP server lifecycle based on config

### Scenario 3: Independence Verification (P1 - Important)
**Goal**: Validate daemon runs independently of project directory

**Steps**:
1. After fresh installation (Scenario 1)
2. Note current working directory (project root)
3. Start daemon (Scenario 2)
4. Verify health endpoint responds
5. Remove project directory (or change to different directory)
6. Verify health endpoint still responds
7. Verify MCP server can process requests
8. Stop daemon

**Expected Outcome**: Daemon continues running without project directory

### Scenario 4: Reinstallation (P1 - Important)
**Goal**: Validate reinstallation is safe and idempotent

**Steps**:
1. After fresh installation (Scenario 1)
2. Run `graphiti-mcp daemon install` again
3. Verify installation detects existing venv
4. Verify "already exists" messages shown
5. Verify no errors or warnings
6. Verify daemon still functional

**Expected Outcome**: Reinstallation is idempotent and safe

### Scenario 5: Error Scenarios (P2 - Nice to have)
**Goal**: Validate error handling for common failures

**Test Cases**:
- Python < 3.10 installed
- Insufficient disk space
- No write permissions to `~/.graphiti/`
- Repository not found (run from wrong directory)
- Service registration fails (no admin privileges)

**Expected Outcome**: Clear error messages with troubleshooting guidance

## Test Approach

### Test Framework
**Recommended**: pytest with fixtures

**Rationale**:
- Existing tests already use pytest
- Fixture support for setup/teardown (create/remove `~/.graphiti/`)
- Platform detection support via `sys.platform`
- Subprocess execution for `graphiti-mcp daemon install`

### Test Structure

```python
# mcp_server/tests/test_e2e_installation.py

class TestE2EInstallation:
    """End-to-end installation tests on clean system."""

    @pytest.fixture
    def clean_graphiti_dir(self):
        """Remove ~/.graphiti/ before test, restore after."""
        graphiti_path = Path.home() / ".graphiti"
        backup_path = None

        if graphiti_path.exists():
            backup_path = Path.home() / ".graphiti.backup"
            shutil.move(graphiti_path, backup_path)

        yield graphiti_path

        # Cleanup: remove test installation
        if graphiti_path.exists():
            shutil.rmtree(graphiti_path)

        # Restore original if existed
        if backup_path and backup_path.exists():
            shutil.move(backup_path, graphiti_path)

    def test_fresh_installation(self, clean_graphiti_dir):
        """Test Scenario 1: Fresh installation."""
        # Run: graphiti-mcp daemon install
        # Verify: directory structure
        # Verify: service registered

    def test_service_lifecycle(self, clean_graphiti_dir):
        """Test Scenario 2: Service start/stop."""
        # Install daemon
        # Start service
        # Query health endpoint
        # Stop service

    def test_independence_from_project_dir(self, clean_graphiti_dir, tmp_path):
        """Test Scenario 3: Independence verification."""
        # Install daemon
        # Start daemon
        # Change to different directory
        # Verify daemon still responds
```

### Platform-Specific Considerations

**Windows**:
- NSSM service registration requires admin privileges
- Test must either:
  - Skip service registration (test install only)
  - Run with admin privileges (document requirement)
  - Mock service registration (unit test approach)

**macOS/Linux**:
- systemd/launchd service registration may require sudo
- Same approaches as Windows

**Recommendation**: Document manual testing steps for service registration, automate everything else

### Health Endpoint Verification

**Approach**:
1. Start bootstrap service
2. Wait for MCP server to start (poll with timeout)
3. Send HTTP GET request to `http://localhost:{PORT}/health`
4. Verify response: `200 OK` with JSON payload
5. Verify payload contains expected fields (version, status, etc.)

**Tooling**: `requests` library for HTTP client

### Test Execution Time

**Estimated Duration**:
- Scenario 1 (Fresh Installation): 30-60 seconds (venv creation + package install)
- Scenario 2 (Service Lifecycle): 15-30 seconds (service start/stop)
- Scenario 3 (Independence): 10-20 seconds (directory change + health check)
- Scenario 4 (Reinstallation): 20-30 seconds (detect existing + skip)
- Scenario 5 (Error Scenarios): 5-10 seconds each (fast failures)

**Total**: ~2-3 minutes for full test suite

### CI/CD Integration

**Challenges**:
- CI runners may not have admin privileges
- CI runners may not allow service installation
- CI runners may have restricted filesystem access

**Recommended Approach**:
1. **Automated Tests** (CI-friendly):
   - Test Scenario 1 with mocked service registration
   - Test Scenario 4 (idempotent reinstall)
   - Test Scenario 5 (error scenarios)

2. **Manual Tests** (documented):
   - Test Scenario 2 (requires service registration)
   - Test Scenario 3 (requires running service)

## Tooling Requirements

### Python Packages (already available)
- pytest - test framework
- requests - HTTP client for health endpoint
- subprocess - run CLI commands
- shutil - directory operations
- pathlib - path manipulation

### Additional Tooling (optional)
- pytest-timeout - prevent hanging tests
- pytest-xdist - parallel test execution
- pytest-cov - coverage reporting

### Platform-Specific Tools (manual testing)
- Windows: NSSM (already used by installer)
- macOS: launchctl (system utility)
- Linux: systemctl (system utility)

## Manual Testing Steps

### Windows (NSSM Service)

**Prerequisites**: Administrator privileges

**Steps**:
1. Open PowerShell as Administrator
2. Remove existing installation: `Remove-Item -Recurse -Force $env:USERPROFILE\.graphiti`
3. Run installer: `graphiti-mcp daemon install`
4. Verify service: `nssm status graphiti-mcp-daemon`
5. Start service: `nssm start graphiti-mcp-daemon`
6. Check health: `Invoke-WebRequest http://localhost:6274/health`
7. Stop service: `nssm stop graphiti-mcp-daemon`
8. Verify logs: `Get-Content $env:USERPROFILE\.graphiti\logs\bootstrap.log`

### macOS (launchd)

**Prerequisites**: May require sudo for service installation

**Steps**:
1. Remove existing: `rm -rf ~/.graphiti`
2. Run installer: `graphiti-mcp daemon install`
3. Load service: `launchctl load ~/Library/LaunchAgents/com.graphiti.mcp.daemon.plist`
4. Check status: `launchctl list | grep graphiti`
5. Check health: `curl http://localhost:6274/health`
6. Unload service: `launchctl unload ~/Library/LaunchAgents/com.graphiti.mcp.daemon.plist`
7. View logs: `tail ~/.graphiti/logs/bootstrap.log`

### Linux (systemd)

**Prerequisites**: May require sudo for service installation

**Steps**:
1. Remove existing: `rm -rf ~/.graphiti`
2. Run installer: `graphiti-mcp daemon install`
3. Enable service: `systemctl --user enable graphiti-mcp-daemon`
4. Start service: `systemctl --user start graphiti-mcp-daemon`
5. Check status: `systemctl --user status graphiti-mcp-daemon`
6. Check health: `curl http://localhost:6274/health`
7. Stop service: `systemctl --user stop graphiti-mcp-daemon`
8. View logs: `journalctl --user -u graphiti-mcp-daemon`

## Documentation Requirements

### Test Documentation
- [ ] Create `mcp_server/tests/README_E2E.md` with manual test instructions
- [ ] Document platform-specific service commands
- [ ] Document admin privilege requirements
- [ ] Document expected test output

### User Documentation
- [ ] Update `claude-mcp-installer/instance/CLAUDE_INSTALL.md` with:
  - Clean system requirements
  - Expected installation directory structure
  - Service verification steps
  - Troubleshooting guide

## Implementation Recommendations

### Phase 1: Automated Tests (CI-friendly)
**Priority**: P0
**Estimated Effort**: 4-6 hours

1. Create `mcp_server/tests/test_e2e_installation.py`
2. Implement Scenario 1 with mocked service registration
3. Implement Scenario 4 (idempotent reinstall)
4. Implement Scenario 5 (error scenarios)
5. Add pytest fixtures for clean state management

### Phase 2: Manual Test Documentation
**Priority**: P1
**Estimated Effort**: 2-3 hours

1. Create `mcp_server/tests/README_E2E.md`
2. Document Scenario 2 (service lifecycle) for each platform
3. Document Scenario 3 (independence verification)
4. Document expected outputs and troubleshooting steps

### Phase 3: Health Endpoint Integration
**Priority**: P1
**Estimated Effort**: 2-3 hours

1. Add health endpoint query to automated tests
2. Add timeout and retry logic for service startup
3. Verify response schema matches expected format
4. Document health endpoint contract

## Risks and Mitigations

### Risk 1: Service Registration Requires Admin
**Impact**: Cannot fully automate E2E test in CI

**Mitigation**:
- Mock service registration for automated tests
- Document manual testing steps
- Run manual tests on release candidates

### Risk 2: Test Flakiness (Timing Issues)
**Impact**: Service startup may take variable time

**Mitigation**:
- Add retry logic with exponential backoff
- Use pytest-timeout to prevent hangs
- Set reasonable timeouts (30-60 seconds)

### Risk 3: Platform-Specific Failures
**Impact**: Test may pass on one platform, fail on another

**Mitigation**:
- Run tests on all platforms (Windows, macOS, Linux)
- Use CI matrix builds
- Document platform-specific gotchas

### Risk 4: Cleanup Failure Leaves System Dirty
**Impact**: Failed test may leave `~/.graphiti/` in bad state

**Mitigation**:
- Use pytest fixtures with robust cleanup
- Add cleanup to test teardown (runs even on failure)
- Document manual cleanup steps

## Success Criteria

### Automated Tests
- [x] Fresh installation creates expected directory structure
- [x] Venv contains installed mcp_server package
- [x] CLI wrappers are generated and valid
- [x] Reinstallation is idempotent
- [x] Error scenarios handled gracefully

### Manual Tests (Documented)
- [ ] Service registration succeeds (platform-specific)
- [ ] Service starts and MCP server responds on health endpoint
- [ ] Daemon runs independently of project directory
- [ ] Service survives system reboot and auto-starts (P1)
- [ ] Logs are written to `~/.graphiti/logs/`

### Documentation
- [ ] Manual test instructions for all platforms
- [ ] Troubleshooting guide for common failures
- [ ] Expected directory structure documented
- [ ] Admin privilege requirements documented

## Next Steps (Implementation Phase)

1. Create `mcp_server/tests/test_e2e_installation.py` with Scenario 1, 4, 5
2. Add pytest fixtures for clean state management
3. Create `mcp_server/tests/README_E2E.md` with manual test instructions
4. Update `claude-mcp-installer/instance/CLAUDE_INSTALL.md` with verification steps
5. Run automated tests on all platforms (Windows, macOS, Linux)
6. Execute manual tests and document results
7. Update story acceptance criteria with test results

## References

- [Story 5: End-to-end installation test](5-end-to-end-installation-test.md)
- [Story 4: Fix NSSM service configuration](4-fix-nssm-service-configuration.md)
- Existing tests: `mcp_server/tests/test_full_install_flow.py`
- Existing tests: `mcp_server/tests/test_package_installation.py`
- DaemonManager: `mcp_server/daemon/manager.py`
- BootstrapService: `mcp_server/daemon/bootstrap.py`
